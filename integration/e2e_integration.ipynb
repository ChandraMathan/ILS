{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is end to end integration. processing steps as stated as a natural language. this is converted to actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "instruction_dir = 'process_steps.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'process': 'navigate to url', 'data': 'http://localhost:3000/webtrain1'}, 1: {'process': 'enter data in', 'data': {'field name': 'First Name', 'value': 'First name test'}}}\n"
     ]
    }
   ],
   "source": [
    "#actions to perform:\n",
    "\n",
    "process_steps = [\"navigate to url:http://localhost:3000/webtrain1\", \"enter 'First name test' in field 'First Name'\"]\n",
    "\n",
    "#pre processing instructions: split in to instructions and data \n",
    "\n",
    "instruction_data = {}\n",
    "for index in range(len(process_steps)):\n",
    "    instruction_data[index] = {}\n",
    "    if \"navigate to url:\" in process_steps[index]:\n",
    "        instruction_data[index]['process'] = 'navigate to url'\n",
    "        instruction_data[index]['data'] = process_steps[index].replace('navigate to url:',\"\")\n",
    "    else:\n",
    "\n",
    "        instruction_data[index]['process'] = 'enter data in'\n",
    "        instruction_data[index]['data'] = {}\n",
    "        \n",
    "\n",
    "        pos = [pos for pos, char in enumerate(process_steps[index]) if char == \"'\"]\n",
    "        instruction_data[index]['data']['field name'] = process_steps[index][pos[2]:pos[3]+1].strip(\"'\")\n",
    "        instruction_data[index]['data']['value'] = process_steps[index][pos[0]:pos[1]+1].strip(\"'\")\n",
    "\n",
    "print(instruction_data)\n",
    "\n",
    "with open(instruction_dir, 'wb') as f:\n",
    "            pickle.dump(instruction_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the output of test_setup\n",
    "with open(instruction_dir, 'rb') as f:\n",
    "    instruction_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##set system path to include relevent modules\n",
    "import sys\n",
    "import pathlib\n",
    "import os\n",
    "root_folder = pathlib.Path(os.getcwd()).parent.resolve()\n",
    "script_dir = os.path.join(root_folder, \"DQN\")\n",
    "sys.path.append(os.path.dirname(script_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing /Users/ml/Desktop/ILS/DQN/__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 09:00:04.080925: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 09:00:08.321827: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#fetch action for each instruction\n",
    "from DQN.dqn_execution_nlp import DQNExecution #import dqn module for prediction\n",
    "from integration.nlp_to_action.env_setup_nlp import EnvNlp\n",
    "\n",
    "#instantiate environment\n",
    "output_sequence_length = 5\n",
    "checkpoint_path = './nlp_to_action/checkpoint_nlp_action.pth'\n",
    "vocab_data = [\"navigate\", \"to\", \"click\", \"on\", \"enter\",\"data\",\"in\",\"the\",\"field\"]\n",
    "\n",
    "#nlp_action_dict\n",
    "\n",
    "nlp_action_dict = { \n",
    "                    0: \n",
    "                        { \n",
    "                        \"nl\": \"navigate to webpage\",\n",
    "                        \"action\": 0\n",
    "                        },\n",
    "                     1: \n",
    "                        { \n",
    "                        \"nl\": \"click on button\",\n",
    "                        \"action\": 1\n",
    "                        },\n",
    "                     2:\n",
    "                        { \n",
    "                        \"nl\": \"enter data in\",\n",
    "                        \"action\": 2\n",
    "                        }\n",
    "                }\n",
    "\n",
    "env_nlp = EnvNlp(training_data = \"\", vocabulary = vocab_data, max_tokens=100, output_sequence_length = output_sequence_length, nlp_action_dict = nlp_action_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "execute = DQNExecution(state_size = output_sequence_length, action_size = 3,env = env_nlp, checkpoint_path = checkpoint_path) #, num_states, num_vertical_grid, num_horizontal_grid, env2d, checkpoint_path)\n",
    "\n",
    "\n",
    "def fetch_actions(instruction, env):\n",
    "    state_arr = []\n",
    "    state_arr.append(instruction)\n",
    "    state = env.get_token(state_arr)\n",
    "    action = execute.dqn_execute(state)\n",
    "\n",
    "    return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location the input field\n",
    "\n",
    "#instantiate environment\n",
    "\"\"\"\n",
    "Environment behaviour is defined\n",
    "\"\"\"\n",
    "from DQN.env_setup import EnvWeb2D\n",
    "from DQN.dqn_execution import DQNExecution as DQNExecutionLocation\n",
    "\n",
    "window_size = (1200,1000)\n",
    "num_horizontal_grid = 10\n",
    "num_vertical_grid = 10\n",
    "\n",
    "grid = (num_vertical_grid, num_horizontal_grid)\n",
    "num_states = 20 #this is based on \n",
    "\n",
    "dict_web_dir = 'data/element_dictionary.pkl' #location of input and label fields and grid numbers stored as dictionary after processing\n",
    "screenshots_dir = 'screenshots/' #directory to help visulaization\n",
    "\n",
    "env2d = EnvWeb2D(dict_web_dir, num_states,grid, window_size)\n",
    "\n",
    "#define checkpoint for trining and testing\n",
    "checkpoint_path = 'checkpoint_label_input.pth'\n",
    "\n",
    "\n",
    "execute_location = DQNExecutionLocation(num_states, num_vertical_grid, num_horizontal_grid, env2d, checkpoint_path)\n",
    "\n",
    "dict_label_location =  env2d.get_data()\n",
    "\n",
    "def fetch_location(execute_location,state, window_size):\n",
    "    location = execute_location.dqn_execute(state/(max(window_size)))\n",
    "\n",
    "    return location\n",
    "\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get state\n",
    "import numpy as np\n",
    "def get_state(label_index,webpage,state_size,dict_label_location):\n",
    "    \n",
    "    state = dict_label_location[webpage]['state'][label_index]\n",
    "\n",
    "    if len(state)< state_size:\n",
    "        for _ in range(0, state_size - len(state)):\n",
    "            state = np.append(state, 0)\n",
    "\n",
    "    return state #/max(window_size) #note this normalization is based on min = 0, and (x-x_min)/(x_max - x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "        \n",
    "\n",
    "def get_label_index(webpage,label_name):       \n",
    "    chrome_options = Options()\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(webpage)\n",
    "    id_lst = []\n",
    "    ids = driver.find_elements(\"xpath\",\"//label\")\n",
    "    for id in ids:\n",
    "        id_lst.append(id.text)\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    if label_name in id_lst:\n",
    "        return id_lst.index(label_name)\n",
    "    \n",
    "    else:\n",
    "        return \"label not found!\"\n",
    "    \n",
    "    \n",
    "\n",
    "#label_index = get_label_index(\"http://localhost:3000/webtest1\",\"First Name\")\n",
    "#print(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navigation_web import NavigateWeb\n",
    "import pickle\n",
    "\n",
    "\n",
    "dict_web_dir = 'data/element_dictionary.pkl' #location of input and label fields and grid numbers stored as dictionary after processing\n",
    "screenshots_dir = 'screenshots/' #directory to help visulaization\n",
    "#view the output of test_setup\n",
    "\n",
    "with open(dict_web_dir, 'rb') as f:\n",
    "    dict_web_elements = pickle.load(f)\n",
    "\n",
    "#print(dict_web_elements['http://localhost:3000/webtrain1']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:352: UserWarning: name used for saved screenshot does not match file type. It should end with a `.png` extension\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "web_page = \"\"\n",
    "nav_web_test = NavigateWeb(window_size, grid)\n",
    "for item in instruction_data:\n",
    "    instruction = instruction_data[item]['process']\n",
    "    action = fetch_actions(instruction, env_nlp)\n",
    "\n",
    "    if type(instruction_data[item]['data']) == dict:\n",
    "        field_name = instruction_data[item]['data']['field name']\n",
    "        field_value = instruction_data[item]['data']['value']\n",
    "        label_index_n = get_label_index(web_page,field_name)\n",
    "        state = get_state(label_index_n,web_page,num_states,dict_label_location)\n",
    "        grid_num = fetch_location(execute_location,state, window_size)\n",
    "        nav_web_test.html_size()\n",
    "        coordinates = nav_web_test.coordinates_from_data(grid_num,dict_web_elements[web_page])\n",
    "        nav_web_test.nav_web(coordinates, field_value)\n",
    "        time.sleep(5)\n",
    "        nav_web_test.screenshots(screenshots_dir)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        web_page = instruction_data[item]['data']\n",
    "\n",
    "    if action == 0:\n",
    "        nav_web_test.open_webpage(web_page)\n",
    "        \n",
    "nav_web_test.close_webpage()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
