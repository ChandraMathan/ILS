{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 09:45:41.882018: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Image \u001b[39mas\u001b[39;00m IPyImage\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m label_map_util\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m config_util\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mobject_detection\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m visualization_utils \u001b[39mas\u001b[39;00m viz_utils\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: a file path.\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  \n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detections(image_np, boxes, classes, scores, category_index, figsize=(12, 16), image_name=None):\n",
    "  \"\"\"Wrapper function to visualize detections.\n",
    "\n",
    "  Args:\n",
    "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
    "      and match the keys in the label map.\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    category_index: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    figsize: size for the figure.\n",
    "    image_name: a name for the image file.\n",
    "  \"\"\"\n",
    "  image_np_with_annotations = image_np.copy()\n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_annotations,\n",
    "      boxes,\n",
    "      classes,\n",
    "      scores,\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=0.8)\n",
    "  if image_name:\n",
    "    plt.imsave(image_name, image_np_with_annotations)\n",
    "  else:\n",
    "    plt.imshow(image_np_with_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detections_tensor(image_np, boxes, classes, scores, category_index, figsize=(12, 16),image_name=None):\n",
    "  \n",
    "  \"\"\"Draws bounding boxes, masks, and keypoints on batch of image tensors.\n",
    "  Args:\n",
    "    images: A 4D uint8 image tensor of shape [N, H, W, C]. If C > 3, additional\n",
    "      channels will be ignored. If C = 1, then we convert the images to RGB\n",
    "      images.\n",
    "    boxes: [N, max_detections, 4] float32 tensor of detection boxes.\n",
    "    classes: [N, max_detections] int tensor of detection classes. Note that\n",
    "      classes are 1-indexed.\n",
    "    scores: [N, max_detections] float32 tensor of detection scores.\n",
    "    category_index: a dict that maps integer ids to category dicts. e.g.\n",
    "      {1: {1: 'dog'}, 2: {2: 'cat'}, ...}\n",
    "    \n",
    "    Returns:\n",
    "    4D image tensor of type uint8, with boxes drawn on top.\n",
    "    \"\"\"\n",
    "\n",
    "  img_tensor = viz_utils.draw_bounding_boxes_on_image_tensors(\n",
    "      image_np,\n",
    "      boxes,\n",
    "      classes,\n",
    "      scores,\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=0.7)\n",
    "  \n",
    "  arr_ = np.squeeze(img_tensor) # you can give axis attribute if you wanna squeeze in specific dimension\n",
    "  plt.imshow(arr_)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate numpy of images and visualize data\n",
    "def viz_data(path_file_name):\n",
    "    \"\"\" a list of file path names are provided \"\"\"\n",
    "    train_images_np = []\n",
    "    for image_item in path_file_name:\n",
    "        train_images_np.append(load_image_into_numpy_array(image_item))\n",
    "        \n",
    "        plt.rcParams['axes.grid'] = False\n",
    "        plt.rcParams['xtick.labelsize'] = False\n",
    "        plt.rcParams['ytick.labelsize'] = False\n",
    "        plt.rcParams['xtick.top'] = False\n",
    "        plt.rcParams['xtick.bottom'] = False\n",
    "        plt.rcParams['ytick.left'] = False\n",
    "        plt.rcParams['ytick.right'] = False\n",
    "        plt.rcParams['figure.figsize'] = [14, 7]\n",
    "\n",
    "\n",
    "    for idx, train_image_np in enumerate(train_images_np):\n",
    "        plt.subplot(2, 3, idx+1)\n",
    "        plt.imshow(train_image_np)\n",
    "        plt.show()\n",
    "    \n",
    "    return train_images_np\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100.jpg', '101.jpg']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'viz_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m file_names \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(x)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m file_names_sorted]\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(file_names)\n\u001b[0;32m---> 20\u001b[0m train_images_np \u001b[39m=\u001b[39m viz_data(file_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'viz_data' is not defined"
     ]
    }
   ],
   "source": [
    "#this block fetches the image data and sorts them in order in line with other scripts and converted to numpy\n",
    "\n",
    "#image data file path\n",
    "data_dir = \"..//data\"\n",
    "#get all the jpeg file names \n",
    "file_names_images = []\n",
    "os.chdir(data_dir)\n",
    "for file in glob.glob(\"*.jpg\"):\n",
    "    file_names_images.append(file)\n",
    "\n",
    "#sort these in order. note that the naming of file is it should start from '100,101,...'. \n",
    "#this format is validated in 'retinanet_labelImg'\n",
    "file_names_sorted = []\n",
    "for file in file_names_images:\n",
    "    file_names_sorted.append(int(file[0:3]))\n",
    "\n",
    "file_names_sorted.sort()\n",
    "file_names = [str(x)+'.jpg' for x in file_names_sorted]\n",
    "\n",
    "train_images_np = viz_data(file_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch ground truth boxes and indices class list in .npy format \n",
    "#these 2 files are generated from another script called bbox\n",
    "\n",
    "gt_boxes = np.load('../data/bbox.npy', allow_pickle=True)\n",
    "indices_class_list = np.load('../data/indices_class_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define category index\n",
    "num_classes = 3\n",
    "input_field_id = 1\n",
    "dropdown_id = 2\n",
    "text_id = 3\n",
    "\n",
    "category_index = {\n",
    "    input_field_id: {'id': input_field_id, 'name': 'Input Field'},\n",
    "    dropdown_id:{'id':dropdown_id, 'name':'Drop Down'},\n",
    "    text_id:{'id':text_id, 'name':'Text'}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class labels to one-hot; convert everything to tensors.\n",
    "# The `label_id_offset` here shifts all classes by a certain number of indices;\n",
    "# we do this here so that the model receives one-hot labels where non-background\n",
    "# classes start counting at the zeroth index. This is ordinarily just handled\n",
    "# automatically in our training binaries, but we need to reproduce it here.\n",
    "label_id_offset = 1\n",
    "train_image_tensors = []\n",
    "gt_classes_one_hot_tensors = []\n",
    "gt_box_tensors = []\n",
    "for (train_image_np, gt_box_np,indices_class) in zip(\n",
    "    train_images_np, gt_boxes,indices_class_list):\n",
    "  train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(\n",
    "      train_image_np, dtype=tf.float32), axis=0))\n",
    "  gt_box_tensors.append(tf.convert_to_tensor(gt_box_np, dtype=tf.float32))\n",
    "  zero_indexed_groundtruth_classes = indices_class-1\n",
    "  gt_classes_one_hot_tensors.append(tf.one_hot(\n",
    "      zero_indexed_groundtruth_classes, num_classes))\n",
    "\n",
    "print('Done prepping data.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for multiple object detection\n",
    "dummy_scores = np.array([1.0], dtype=np.float32)  # give boxes a score of 100%\n",
    "print(type(train_images_np[0]))\n",
    "plt.figure(figsize=(30, 15))\n",
    "for idx in range(1):\n",
    "  plt.subplot(2, 3, idx+1)\n",
    "  dummy_scores = tf.convert_to_tensor(np.ones((1, gt_boxes[idx].shape[0]),dtype=np.float32))\n",
    "\n",
    "  plot_detections_tensor(\n",
    "      tf.convert_to_tensor(np.expand_dims(train_images_np[idx], axis=0)),\n",
    "      tf.convert_to_tensor(np.expand_dims(gt_boxes[idx], axis=0)),\n",
    "      tf.convert_to_tensor(np.expand_dims(indices_class_list[idx], axis=0)),\n",
    "      dummy_scores, category_index)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
