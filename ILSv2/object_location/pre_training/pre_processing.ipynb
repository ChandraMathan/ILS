{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains scripts to:\n",
    "1. Resize image to 640 x 640\n",
    "2. use labelImg to create bounding box\n",
    "3. convert the xml from 'labelImg' to two numpy file: bounding box and class indexes of the corresponding bounding box\n",
    "4. define category index to be used while training and inference. To be updated manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define resized dimention\n",
    "resized_height = 640\n",
    "resized_width = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : Resize train and test images\n",
    "\n",
    "#resize train image\n",
    "\n",
    "input_file_location = '../data/training_data/'\n",
    "output_file_location = '../data/training_data/processed_images/'\n",
    "\n",
    "image_file_names = []\n",
    "for file in glob.glob(input_file_location+\"*.jpg\"):\n",
    "    image_file_names.append(file)\n",
    "\n",
    "\n",
    "for img in image_file_names:\n",
    "    image = cv2.imread(img)\n",
    "    resize_image = cv2.resize(image, (resized_width, resized_height))\n",
    "    cv2.imwrite(output_file_location+img[-7:],resize_image)\n",
    "\n",
    "#resize test image\n",
    "\n",
    "input_file_location = '../data/test_data/'\n",
    "output_file_location = '../data/test_data/processed_images/'\n",
    "\n",
    "image_file_names = []\n",
    "for file in glob.glob(input_file_location+\"*.jpg\"):\n",
    "    image_file_names.append(file)\n",
    "\n",
    "\n",
    "for img in image_file_names:\n",
    "    image = cv2.imread(img)\n",
    "    resize_image = cv2.resize(image, (resized_width, resized_height))\n",
    "    cv2.imwrite(output_file_location+img[-7:],resize_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/test_data/100.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/test_data/100.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/100.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/100.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/101.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/101.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/102.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/102.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/103.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/103.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/104.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/104.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/105.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/105.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/106.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/106.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/107.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/107.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/108.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/108.xml\n",
      "Image:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/109.jpg -> Annotation:/Users/ml/Desktop/ILS/ILSv2/object_location/data/training_data/processed_images/109.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 2: create bbox using 'labelImg' as save the xml\n",
    "\n",
    "# !important: while labelling ensure that labels are numerical, starting from 100. 100,101,102,103,..... etc.\n",
    "#as the code is designed to handle only the numerals.\n",
    "os.system(\"labelimg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Convert xml to 2 '.npy' files.\n",
    "\n",
    "training_file_dir = '../data/training_data/processed_images/'\n",
    "\n",
    "#get all the xml file names generated after labelling from previous step and the corresponding image file names\n",
    "file_names_xml = []\n",
    "for file in glob.glob(training_file_dir+\"*.xml\"):\n",
    "    file_names_xml.append(file)\n",
    "\n",
    "file_names_images = []\n",
    "for file in glob.glob(training_file_dir+\"*.jpg\"):\n",
    "    file_names_images.append(file)\n",
    "\n",
    "\n",
    "#ensure number of images equals number of xml and then organize file name in ascending order\n",
    "\n",
    "if len(file_names_xml) != len(file_names_images):\n",
    "    print(\"Error: Inconsistent number of xml and image files\")\n",
    "\n",
    "#sort xml files \n",
    "file_names_sorted = []\n",
    "for file in file_names_xml:\n",
    "    file_names_sorted.append(int(file[-7:-4]))\n",
    "\n",
    "file_names_sorted.sort()\n",
    "file_names = [str(x)+'.xml' for x in file_names_sorted]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100.xml', '101.xml', '102.xml', '103.xml', '104.xml', '105.xml', '106.xml', '107.xml', '108.xml', '109.xml']\n"
     ]
    }
   ],
   "source": [
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert xml file to format to be consumed by retina net algorithm\n",
    "\n",
    "bbox_formatted_all = []\n",
    "name_obj_all = []\n",
    "for file_name in file_names:\n",
    "    \n",
    "    tree = ET.parse(training_file_dir+file_name)\n",
    "    \n",
    "    root = tree.getroot()\n",
    "\n",
    "    bbox_formatted= []\n",
    "    name_obj_formatted= []\n",
    "    obj_bbox = root.findall('./object')\n",
    "    name_obj = []\n",
    "    for item in obj_bbox:\n",
    "        bbox = []\n",
    "        name_obj.append(item.find('name').text)\n",
    "        bbox_cord= item.find('./bndbox')\n",
    "        bbox.append(\n",
    "            [\n",
    "            bbox_cord.find(\"ymin\").text,\n",
    "            bbox_cord.find(\"xmin\").text,\n",
    "            bbox_cord.find(\"ymax\").text,\n",
    "            bbox_cord.find(\"xmax\").text\n",
    "            ]  \n",
    "        )\n",
    "        bbox_formatted.append((bbox[0]))\n",
    "    bbox_formatted_all.append(np.array(bbox_formatted, dtype = np.float32)/640.0) #640 is both and width dimention.\n",
    "    name_obj_all.append(np.array(name_obj).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "#save bbox as .npy file\n",
    "bbox_fn = training_file_dir+'bbox.npy'\n",
    "with open(bbox_fn, 'wb') as f:\n",
    "    np.save(f, bbox_formatted_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/gd1m2zgn4hzgrrx4xcds_bg80000gp/T/ipykernel_2209/877041472.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  name_obj_all = np.array(name_obj_all).astype(object)\n"
     ]
    }
   ],
   "source": [
    "#save index of the class list\n",
    "indices_class_fn = training_file_dir+'indices_class_list.npy'\n",
    "\n",
    "name_obj_all = np.array(name_obj_all).astype(object)\n",
    "with open(indices_class_fn, 'wb') as f:\n",
    "    np.save(f, name_obj_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Example of multi class\\n\\n    num_classes = 3\\n    input_field_id = 1\\n    dropdown_id = 2\\n    text_id = 3\\n\\n    category_index = {\\n        input_field_id: {'id': input_field_id, 'name': 'Input Field'},\\n        dropdown_id:{'id':dropdown_id, 'name':'Drop Down'},\\n        text_id:{'id':text_id, 'name':'Text'}\\n        }\\n\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 4: Define category index\n",
    "\n",
    "num_classes = 1\n",
    "input_field_id = 1\n",
    "\n",
    "category_index = {\n",
    "        input_field_id: {'id': input_field_id, 'name': 'Input Field'}\n",
    "        }\n",
    "\n",
    "\n",
    "file_path = training_file_dir+'category_index.pickle'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(category_index, file)\n",
    "\n",
    "\n",
    "\"\"\" Example of multi class\n",
    "\n",
    "    num_classes = 3\n",
    "    input_field_id = 1\n",
    "    dropdown_id = 2\n",
    "    text_id = 3\n",
    "\n",
    "    category_index = {\n",
    "        input_field_id: {'id': input_field_id, 'name': 'Input Field'},\n",
    "        dropdown_id:{'id':dropdown_id, 'name':'Drop Down'},\n",
    "        text_id:{'id':text_id, 'name':'Text'}\n",
    "        }\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
